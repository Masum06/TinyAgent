{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCW6TQf62EfEmA3HIW9lv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masum06/TinyAgent/blob/main/TinyAgent_Colab_Noebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")"
      ],
      "metadata": {
        "id": "Wsl---_28-6m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_set_env(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2jTVAqy9BQf",
        "outputId": "68d969ef-f337-4f2e-ea8f-8c71be630dc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tiktoken"
      ],
      "metadata": {
        "id": "-XbzuMKAMrk-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TinyAgent"
      ],
      "metadata": {
        "id": "698cBe76CJNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tiktoken\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "lEIqZLGKx7s-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class TinyAgent:\n",
        "\n",
        "    def __init__(self, model, tokenizer=None, debug=False):\n",
        "\n",
        "        self.model = model\n",
        "        self.messages = []\n",
        "        self.max_tokens = 3072\n",
        "        self.debug = False\n",
        "        self.reasoning_effort = \"low\"\n",
        "        self.temperature = 1\n",
        "\n",
        "    def clear_messages(self):\n",
        "        self.messages = list()\n",
        "\n",
        "    def add_message(self,message_type, message):\n",
        "        self.messages.append({\"role\": message_type, \"content\":message})\n",
        "\n",
        "    def add_system_message(self, message):\n",
        "        self.add_message(\"system\", message)\n",
        "\n",
        "    def add_user_message(self, message):\n",
        "        self.add_message(\"user\", message)\n",
        "\n",
        "    def set_max_tokens(self, max_tokens):\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def set_debug(self, debug):\n",
        "        self.debug = debug\n",
        "\n",
        "    def set_reasoning_effort(self, reasoning_effort):\n",
        "        self.reasoning_effort = reasoning_effort\n",
        "\n",
        "    def call(self, prompt=\"\", response_type=\"text\"):\n",
        "        if prompt:\n",
        "            self.add_user_message(prompt)\n",
        "\n",
        "        if \"gpt-5\" in self.model:\n",
        "            response = client.responses.create(\n",
        "                model=self.model,\n",
        "                input=self.messages,\n",
        "                reasoning={\"effort\": self.reasoning_effort},\n",
        "                text={\n",
        "                    \"format\": {\n",
        "                      \"type\": response_type\n",
        "                    },\n",
        "                    \"verbosity\": \"low\"\n",
        "                  },\n",
        "            )\n",
        "            reply = response.output_text\n",
        "            if self.debug:\n",
        "                print(reply)\n",
        "            return reply\n",
        "\n",
        "        elif \"gpt-4\" in self.model:\n",
        "            response = client.responses.create(\n",
        "              model=self.model,\n",
        "              input=self.messages,\n",
        "              temperature=self.temperature,\n",
        "              max_output_tokens=self.max_tokens,\n",
        "              top_p=1,\n",
        "              text={\n",
        "                \"format\": {\n",
        "                  \"type\": response_type # \"text\", \"json_object\"\n",
        "                }\n",
        "              }\n",
        "            )\n",
        "            reply = response.output_text\n",
        "            self.add_message(\"assistant\", reply)\n",
        "            if self.debug:\n",
        "                print(reply)\n",
        "            return reply\n",
        "\n",
        "    def load_json(self,s):\n",
        "        import json\n",
        "        try:\n",
        "            return json.loads(s)\n",
        "        except json.JSONDecodeError:\n",
        "            return None\n",
        "\n",
        "    def call_reply(self):\n",
        "\n",
        "        reply = self.call()\n",
        "\n",
        "        return reply\n",
        "\n",
        "    def call_json(self, prompt=\"\"):\n",
        "        self.add_system_message(\"Reply must be JSON format.\")\n",
        "        if prompt:\n",
        "            self.add_user_message(prompt)\n",
        "        reply = self.call(response_type=\"json_object\")\n",
        "        if not reply:\n",
        "            print(\"Empty reply\")\n",
        "            return None\n",
        "\n",
        "        reply = reply.strip()\n",
        "        if reply.startswith(\"```json\"):\n",
        "            reply = reply[len(\"```json\"):].strip()\n",
        "            if reply.endswith(\"```\"):\n",
        "                reply = reply[:-3].strip()\n",
        "\n",
        "        # Use OR, and guard length\n",
        "        if not (reply.startswith(\"{\") and reply.endswith(\"}\")):\n",
        "            print(\"Not JSON structure\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            return self.load_json(reply)\n",
        "        except Exception:\n",
        "            print(\"Error parsing JSON\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "N6_28Cta9DoB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_agent = TinyAgent(\"gpt-4.1\")"
      ],
      "metadata": {
        "id": "sU2jlGFU_Lgx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_agent.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG5T6-6X_vLp",
        "outputId": "94f5859f-2fac-47e5-f77f-5aa9ac1e2c94"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unstructured Call"
      ],
      "metadata": {
        "id": "TjKzYLqUQKdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_agent.call(\"What's your name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LXmeZ0oN_yFk",
        "outputId": "7869a88a-afa4-4b7f-d701-4398d8d6f8c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I’m ChatGPT—an AI language model created by OpenAI. I don’t have a personal name, but you can just call me ChatGPT! How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_agent.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqS0vd0WAA1v",
        "outputId": "f20c110a-e4f0-4474-a8d1-3d21ca5f93ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user', 'content': \"What's your name?\"},\n",
              " {'role': 'assistant',\n",
              "  'content': 'I’m ChatGPT—an AI language model created by OpenAI. I don’t have a personal name, but you can just call me ChatGPT! How can I help you today?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured Call"
      ],
      "metadata": {
        "id": "7G98SqLFQNBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = tiny_agent.call_json(\"Give me a list of popular math equations in JSON format.\")\n",
        "result"
      ],
      "metadata": {
        "id": "8AhEL49DQO-J",
        "outputId": "eebe3652-e832-4816-fb30-c1d924410d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'math_equations': [{'name': 'Pythagorean Theorem',\n",
              "   'equation': 'a^2 + b^2 = c^2'},\n",
              "  {'name': 'Quadratic Formula',\n",
              "   'equation': 'x = \\\\frac{-b \\\\pm \\\\sqrt{b^2-4ac}}{2a}'},\n",
              "  {'name': \"Euler's Formula\", 'equation': 'e^{ix} = \\\\cos{x} + i\\\\sin{x}'},\n",
              "  {'name': \"Einstein's Mass-Energy Equivalence\", 'equation': 'E = mc^2'},\n",
              "  {'name': 'Area of a Circle', 'equation': 'A = \\\\pi r^2'},\n",
              "  {'name': 'Slope of a Line', 'equation': 'm = \\\\frac{y_2 - y_1}{x_2 - x_1}'},\n",
              "  {'name': \"Newton's Second Law\", 'equation': 'F = ma'},\n",
              "  {'name': 'Logarithm Definition', 'equation': 'y = \\\\log_b x \\\\iff b^y = x'},\n",
              "  {'name': 'Binomial Theorem',\n",
              "   'equation': '(a + b)^n = \\\\sum_{k=0}^{n} {n \\\\choose k} a^{n-k} b^k'},\n",
              "  {'name': 'Derivative Definition',\n",
              "   'equation': \"f'(x) = \\\\lim_{h \\\\to 0} \\\\frac{f(x+h) - f(x)}{h}\"}]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['math_equations'][0]"
      ],
      "metadata": {
        "id": "RITdbQK0QviD",
        "outputId": "66fbbf0b-eaf9-41b9-c041-767487ef89c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Pythagorean Theorem', 'equation': 'a^2 + b^2 = c^2'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7aJgG_n9Q1E1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}